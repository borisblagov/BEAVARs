var documenterSearchIndex = {"docs":
[{"location":"CPZ2023/#CPZ2023","page":"CPZ2023","title":"CPZ2023","text":"","category":"section"},{"location":"Chan2020csv/#Chan2020csv","page":"Chan2020csv","title":"Chan2020csv","text":"","category":"section"},{"location":"BGR2010/#BGR2010","page":"BGR2010","title":"BGR2010","text":"","category":"section"},{"location":"BGR2010/#Minnesota-prior-via-dummy-observations","page":"BGR2010","title":"Minnesota prior via dummy observations","text":"","category":"section"},{"location":"BGR2010/","page":"BGR2010","title":"BGR2010","text":"makeDummiesMinn!(sigma::Vector{Float64},delta::Vector{Float64},lambda,n::Integer,p::Integer,epsi,Y_d1,X_d1)","category":"page"},{"location":"BGR2010/#BEAVARs.makeDummiesMinn!-Tuple{Vector{Float64}, Vector{Float64}, Any, Integer, Integer, Any, Any, Any}","page":"BGR2010","title":"BEAVARs.makeDummiesMinn!","text":"makeDummiesMinn!(sigma::Vector{Float64},delta,lambda,n::Integer,p::Integer,Y_d1))\n\nFills a matrix Y_d and X_d following eq. (5) in Banbura, Giannone, Reichling (2010), JAE, Large Bayesian Autoregressions. \n\nY_d =   beginbmatrix\n         diag(σ_1*δ_1 dots σ_N*δ_n)λ\r\n         mathbf0_n*(p-1) times n\r\n         diag(σ_1 dots σ_n)\r\n         mathbf0_1n times n\n         endbmatrix\n\nX_d = beginbmatrix\n        diag(1dotsp) otimes diag(σ_1 dots σ_n) λ quad mathbf0_n*p1\r\n        mathbf0_nn*p+1\r\n        mathbf0_1n*p  ε\r\n        endbmatrix\n\nInstad of creating the matrix every time, the function uses mutation on matrices called Y_d1 and X_d1.\n\nFor Y_d1 it is the the diagonal of the first (1:n,1:n) block and in the diagonal of the third block n+n*(p-1)+1:n+n*(p-1)+n\n\nFor X_d1 it is the diagonal of the first (n * p x n * p), esesntially X_d1 is populated along its diagonal and only the constant is added at the end\n\nfunction makeDummiesMinn!(sigma::Vector{Float64},delta::Vector{Float64},lambda,n::Integer,p::Integer,epsi,Y_d1,X_d1)\n    CI1_Yd1 = CartesianIndex.(1:n,1:n)  # These are the diagonal indices for the top block \n    CI2_Yd1 = CartesianIndex.(n+n*(p-1)+1:n+n*(p-1)+n,1:n)  # These are the diagonal indices for the block in the middle\n    CI_Xd1 = CartesianIndex.(1:n*p,1:n*p)\n    Y_d1[CI1_Yd1] = sigma.*delta./lambda;\n    Y_d1[CI2_Yd1] = sigma;\n    X_d1[end,end] = epsi;\n    X_d1[CI_Xd1]  = repeat(sigma./lambda,p).*repeat(1:p,inner=n)\n    return Y_d1, X_d1;\nend\n\n\n\n\n\n","category":"method"},{"location":"Chan2020iniw/#Chan2020iniw","page":"Chan2020iniw","title":"Chan2020iniw","text":"","category":"section"},{"location":"Chan2020minn/#Chan2020minn","page":"Chan2020minn","title":"Chan2020minn","text":"","category":"section"},{"location":"Chan2020minn/#Hands-on-example","page":"Chan2020minn","title":"Hands-on example","text":"","category":"section"},{"location":"Chan2020minn/","page":"Chan2020minn","title":"Chan2020minn","text":"We will load the packages first. The package Dates is used only for the example here and is typically not required. TimeSeries is used to generate the needed TimeArray so it is required.  If you don't have these you would have to install them.","category":"page"},{"location":"Chan2020minn/","page":"Chan2020minn","title":"Chan2020minn","text":"julia> using BEAVARs, Time Series\njulia> using Dates     # these are required only for the example, your data may already have a time-series format","category":"page"},{"location":"Chan2020minn/","page":"Chan2020minn","title":"Chan2020minn","text":"Next we will create the setup for the VAR model using the makeSetup() function. The function needs a string to know which structures to initialize. For this model it is \"Chan2020minn\". We will use default values for the VAR setup  but will change the number of lags p=2 and we will have a very small burn in = 20 and n_save = 50. We will not change any hyperparameters, therefore not pass any structure hypto the function makeSetup","category":"page"},{"location":"Chan2020minn/","page":"Chan2020minn","title":"Chan2020minn","text":"julia> model_type, hyp_strct, set_strct = makeSetup(\"Chan2020minn\";n_burn=20,n_save=50,p=2)\n(BEAVARs.Chan2020minn_type(), hypChan2020\n  c1: Float64 0.04\n  c2: Float64 0.01\n  c3: Float64 100.0\n  ρ: Float64 0.8\n  σ_h2: Float64 0.1\n  v_h0: Float64 5.0\n  S_h0: Float64 0.04\n  ρ_0: Float64 0.9\n  V_ρ: Float64 0.04\n  q: Float64 0.5\n  nu0: Int64 3\n, BEAVARs.VARSetup\n  p: Int64 2\n  nsave: Int64 20\n  nburn: Int64 50\n  n_irf: Int64 16\n  n_fcst: Int64 8\n  const_loc: Int64 1\n)","category":"page"},{"location":"Chan2020minn/","page":"Chan2020minn","title":"Chan2020minn","text":"From now on, we will not use the string \"Chan2020minn\" but always use the binding model_type if we ever need to call a function that is model specific.","category":"page"},{"location":"Chan2020minn/","page":"Chan2020minn","title":"Chan2020minn","text":"The final part is to load our data. It has to be a TimeArray, so we will create one using random dates and values. For importing your own data you may use the function readtimearray() from the TimeSeries package.","category":"page"},{"location":"Chan2020minn/","page":"Chan2020minn","title":"Chan2020minn","text":"data = TimeArray(DateTime(2020,1,1):Quarter(1):DateTime(2027,4,1),rand(30,3));\njulia> data = TimeArray(DateTime(2020,1,1):Quarter(1):DateTime(2027,4,1),rand(30,3))\n30×3 TimeArray{Float64, 2, DateTime, Matrix{Float64}} 2020-01-01T00:00:00 to 2027-04-01T00:00:00\n┌─────────────────────┬────────────┬───────────┬──────────┐\n│                     │ A          │ B         │ C        │\n├─────────────────────┼────────────┼───────────┼──────────┤\n│ 2020-01-01T00:00:00 │ 0.00817292 │  0.939333 │ 0.372302 │\n│ 2020-04-01T00:00:00 │   0.420362 │ 0.0207827 │ 0.134192 │\n│          ⋮          │     ⋮      │     ⋮     │    ⋮     │\n│ 2027-04-01T00:00:00 │   0.942019 │  0.414029 │ 0.208983 │\n└─────────────────────┴────────────┴───────────┴──────────┘\n                                            27 rows omitted\n","category":"page"},{"location":"Chan2020minn/","page":"Chan2020minn","title":"Chan2020minn","text":"Now let's generate the data structure required from the package.","category":"page"},{"location":"Chan2020minn/","page":"Chan2020minn","title":"Chan2020minn","text":"julia> data_strct = BEAVARs.makeDataSetup(model_type,data)\nBEAVARs.dataBVAR_TA\n  data_tab: TimeArray{Float64, 2, DateTime, Matrix{Float64}}\n  var_list: Array{Symbol}((3,))","category":"page"},{"location":"Chan2020minn/","page":"Chan2020minn","title":"Chan2020minn","text":"You can see that we did not specify any variable names, thus var_list will simply take the names from the TimeArray. Note that this list is important only in very few specific circumstances such as calculating IRFs using the Cholesky decomposition, where the ordering of the variables matters.","category":"page"},{"location":"Chan2020minn/","page":"Chan2020minn","title":"Chan2020minn","text":"Now we are ready to estimate the model. The generic function is ","category":"page"},{"location":"Chan2020minn/","page":"Chan2020minn","title":"Chan2020minn","text":"julia> out_strct, varSetup = beavar(model_type, set_strct, hyp_strct, data_strct);","category":"page"},{"location":"Constructors/","page":"Constructors","title":"Constructors","text":"hypChan2020","category":"page"},{"location":"Constructors/#BEAVARs.hypChan2020","page":"Constructors","title":"BEAVARs.hypChan2020","text":"hypChan2020()\n\nPopulate a hyperparamater structure for models based on Chan (2020) priors \n\nArguments\n\n    c1: hyperparameter on own lags \n    c2: hyperparameter on other lags\n    c3: hyperparameter on the constant\n    ρ:  ar(1) parameter for the stochastic volatility (Chan2020csv only)\n    σ_h2: variance of the log-volatility (Chan2020csv only)\n\n\n\n\n\n","category":"type"},{"location":"Constructors/","page":"Constructors","title":"Constructors","text":"hypBGR2010","category":"page"},{"location":"Constructors/#BEAVARs.hypBGR2010","page":"Constructors","title":"BEAVARs.hypBGR2010","text":"hypBGR2010()\n\nGenerate a structure with hyperparameters for Banbura, Giannone, and Reichlin (2010) Large Bayesian VARs\n\nArguments\n\nlambda: shrinkage parameter between AR(1) model and maximum likelihood. Default 0.1\nepsi:\n\nExamples\n\nUsing default values. Note that the main function will auto-generate this for you. If you don't plan to change any there is rarely need to ever call it.\n\njulia> hyp = hypBGR2010()\nhypBGR2010\n  lambda: Float64 0.1\n  epsi: Float64 0.001\n\nIf a tighter prior (shrinkage towards AR(1)) is desired due to a larger VAR: \n\njulia> hyp = hypBGR2010(lambda=0.05)\nhypBGR2010\n  lambda: Float64 0.05\n  epsi: Float64 0.001\n\n\n\n\n\n","category":"type"},{"location":"introduction/#General-introduction","page":"Introduction","title":"General introduction","text":"","category":"section"},{"location":"introduction/#Installation","page":"Introduction","title":"Installation","text":"","category":"section"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Installing the package follows the typical Julia scheme","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"pkg> add BEAVARs","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"and","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"julia> using BEAVARs","category":"page"},{"location":"introduction/#Usage","page":"Introduction","title":"Usage","text":"","category":"section"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"The main function of the package is","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"beavar(model_type, set_strct, hyp_strct, data_strct)","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"which calls the relevant models and performs the estimation. Using the package boils down to the correct specification of its arguments. Therefore, before jumping in the details let's sketch them.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"model_type: A custom type of the package, i.e. a special object that allows Julia to know which function to call. \nset_strct:  A structure with general VAR setup such as number of lags, number of draws, etc.\nhyp_strct:  A structure with hyperparameter values for the Bayesian estimation.\ndata_strct: A structure containing your data.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"The first three are generated using a helper function make_setup.","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"makeSetup(model_str::String;p::Int=4,n_burn::Int=1000,n_save::Int=1000,n_irf::Int=16,n_fcst::Int = 8,hyp::BVARmodelHypSetup=hypDefault_strct())","category":"page"},{"location":"introduction/#BEAVARs.makeSetup-Tuple{String}","page":"Introduction","title":"BEAVARs.makeSetup","text":"model_type, hyp_strct, set_strct = makeSetup(model_str::String; p::Int=4,n_burn::Int=1000,n_save::Int=1000,n_irf::Int=16,n_fcst::Int = 8,hyp::BVARmodelHypSetup=hypDefault_strct())\n\nSpecify a model and generate structures for the Bayesian VAR and the hyperparameters.\n\nOnly the first argument is mandatory, rest is optional with default values.\n\nArguments\n\nmodel_str: String, currently supported are \"CPZ2023\", \"Chan2020minn\", \"Chan2020csv\", \"Chan2020iniw\", \"BGR2010\"\np:         number of lags, default is 4\nn_burn:    number of burn-in draws that will be discarded, default is 2000\nn_save:    number of retained draws (total is then nburn + nsave), default is 1000\nn_irf:     horizon of impulse responses, default is 16\nn_fcst:    horizon of forecasting periods, default is 8\nhyp:       hyperparameter structure populated with default values for each model. See the relevant papers/documentation for details. To generate your own see the relevant structures below.\n\nSee also hypChan2020, hypBGR2010.\n\n\n\n\n\n","category":"method"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"The last is generated using the helper function ","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"makeDataSetup(model_type, data_tab::TimeArray; var_list::Vector{Symbol})","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"which is different for evey model. ","category":"page"},{"location":"introduction/","page":"Introduction","title":"Introduction","text":"Next we will estimate a model using a particular example.","category":"page"},{"location":"#BEAVARs.jl-Documentation","page":"Overview","title":"BEAVARs.jl Documentation","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"(Image: Credit Mikelde Ferro: https://www.youtube.com/watch?v=WIYQWK4pkqg&ab_channel=MikedelFerro-Music)","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"BEAVARs.jl: Bayesian Econometric Analysis using Vector Autoregressive models","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"This is a personal package implementing various Bayesian VARs for economic analysis and forecasting. ","category":"page"},{"location":"#Available-models","page":"Overview","title":"Available models","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"VAR models with a single frequency:","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Chan2020minn: BVAR with classical  Minnesota prior (homoscedastic fixed variance-covariance matrix) as in Chan, J.C.C. (2020), Large Bayesian Vecotrautoregressions, P. Fuleky (Eds), Macroeconomic Forecasting in the Era of Big Data, 95-125, Springer, Cham, https://doi.org/10.1007/978-3-030-31150-6, see also joshuachan.org and his pdf.\nChan2020iniw: BVAR with Minnesota prior and an independent normal inverse Wishart (iniw) prior on the variance-covariance matrix  as in Chan, J.C.C. (2020), Large Bayesian Vecotrautoregressions, P. Fuleky (Eds), Macroeconomic Forecasting in the Era of Big Data, 95-125, Springer, Cham, https://doi.org/10.1007/978-3-030-31150-6, see also joshuachan.org and his pdf.\nChan2020csv: BVAR with Minnesota prior and common stochastic volatility (csv) as in Chan, J.C.C. (2020), Large Bayesian Vecotrautoregressions, P. Fuleky (Eds), Macroeconomic Forecasting in the Era of Big Data, 95-125, Springer, Cham, https://doi.org/10.1007/978-3-030-31150-6, see also joshuachan.org and his pdf.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"BGR2010: BVAR with dummy observations as in Banbura, M., Giannone, D., and Reichlin, L. (2010), Large Bayesian vecotr auto regressions, Journal of Applied Econometrics, Vol 25(1), doi.org/10.1002/jae.1137.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Mixed frequency VARs:","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"CPZ2023: Mixed-frequency Bayesian VAR as in Chan, J.C.C., Poon, A, Zhu, D. (2023) High-dimensional conditionally Gaussian state space models with missing data, Journal of Econometrics, Volume 236, Issue 1, September 2023, 105468, https://doi.org/10.1016/j.jeconom.2023.05.005. Important: the mixed-frequency representation in the original paper does not rely on prior assumptions. This version uses the prior from Chan2020iniw above.  ","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Each model is implemented in a separate function, callable using the interface beavar(). See the documetnation for details. Note that notation follows the original reference. Consequently variable and parameter names are different across functions (e.g. lambda_1 in one paper can be c_1 in another, even if they mean the same thing). ","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Some codes have been translated from Matlab, so there is a lot of room for optimization. ","category":"page"},{"location":"#Notes-on-the-name","page":"Overview","title":"Notes on the name","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"The name BEAVARs is an obvious play of words with a misspelled version of my favourite animal.\nIt is also a nod to the BEAR Toolbox - Bayesian  Estimation, Analysis and Regression, which is a powerful Matlab toolbox for estimating various VAR, BVAR, and Panel VAR models. While this is not an attempt to reach the size and scope of BEAR in the Julia ecosystem, there are some clear similarities in the idea of easy estimation of various models.\nThe name does not conform to the widely accepted convention of naming Julia packages (capital letter followed by all lowercase) but it doesn't break any rules either. It isn't the only package with more than one capita letter, e.g. FFT, CUDA, CSV etc. Yes, it's an acronym, which can always be misleading. CSV may mean you comma-separated value, but in my world it stands for common stochastic volatility :). Nevertheless, there should be minial confusion, because it's misspelled on purpose - the name Beaver.jl remains open, and if someone wants to use that we can still distinguish the packages BEAVARs.jl and Beavers.jl easily. ","category":"page"},{"location":"#Acknowledgmenets","page":"Overview","title":"Acknowledgmenets","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"I would like to thank Guillaume Dalle, who, even though it is not associated with this package went out of his way to help me get my first steps in Github and Julia optimization. Also, many users in the Julia discourse helped me often when I was struggling. This community is great.","category":"page"},{"location":"#First-steps","page":"Overview","title":"First steps","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"Consider going to the General introduction next","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Pages = [\"BGR2010.md\", \"Chan2020minn.md\", \"Chan2020csv.md\"]\nDepth = 2","category":"page"},{"location":"#References","page":"Overview","title":"References","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"Banbura, Marta, Giannone, Domenico and Reichlin, Lucrezia, (2010), Large Bayesian vector auto regressions, Journal of Applied Econometrics, 25, issue 1, p. 71-92. https://doi.org/10.1002/jae.1137. ","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Chan, J.C.C. (2020), Large Bayesian Vecotrautoregressions, P. Fuleky (Eds), Macroeconomic Forecasting in the Era of Big Data, 95-125, Springer, Cham, https://doi.org/10.1007/978-3-030-31150-6","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Chan, J.C.C., Poon, A, Zhu, D. (2023) High-dimensional conditionally Gaussian state space models with missing data, Journal of Econometrics, Volume 236, Issue 1, September 2023, 105468, https://doi.org/10.1016/j.jeconom.2023.05.005","category":"page"},{"location":"init_functions/#Initialization-functions-functions","page":"Initialization","title":"Initialization functions functions","text":"","category":"section"},{"location":"init_functions/","page":"Initialization","title":"Initialization","text":"ols(Y,X)","category":"page"},{"location":"init_functions/#BEAVARs.ols-Tuple{Any, Any}","page":"Initialization","title":"BEAVARs.ols","text":"ols(Y,X)\n\nPerforms standard linear regression on two matrices Y and X, returning β as a vector, the vector of residuals ε and the variance σ_sq\n\n\n\n\n\n","category":"method"},{"location":"init_functions/","page":"Initialization","title":"Initialization","text":"mlag(Yfull::Matrix{Float64},p::Integer)","category":"page"},{"location":"init_functions/#BEAVARs.mlag-Tuple{Matrix{Float64}, Integer}","page":"Initialization","title":"BEAVARs.mlag","text":"mlag(Yfull::Matrix{Float64},p::Integer)\nCreates lags of a matrix for a VAR representation with a constant on the right of X\n    Yfull: a matrix of dimensions T+p x N returns a matrix Y with dimensions TxN and X with dimenions Tx(N*p+1)\n\n\n\n\n\n","category":"method"},{"location":"init_functions/","page":"Initialization","title":"Initialization","text":"trainPriors(Z0::Matrix{Float64},p::Int64)","category":"page"},{"location":"init_functions/#BEAVARs.trainPriors-Tuple{Matrix{Float64}, Int64}","page":"Initialization","title":"BEAVARs.trainPriors","text":"trainPriors(Z0::Matrix{Float64},p::Int64)\n\nIndependent AR(p) regressions with constant to estimate prior values for further Bayesian estimation\n\nFor a training sample Z0 with n variables and p lags the function will do column-wise n linear regressions of order p and return a matrix \n\ndeltaP has the constant on the bottom and the lags (1) to (p) in rows [1:end-1,:]\n\n\n\n\n\n","category":"method"},{"location":"init_functions/","page":"Initialization","title":"Initialization","text":"percentile_mat(A, p; dims)","category":"page"}]
}
